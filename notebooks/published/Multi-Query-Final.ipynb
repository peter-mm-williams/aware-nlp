{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "425996ee-4dc8-4337-ae79-d97d9a73b06f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9162748-0ece-450f-b65c-32b62395393f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langchain_community.document_loaders import DataFrameLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "import uuid\n",
    "import os\n",
    "from langchain_core.documents import Document\n",
    "from tqdm import tqdm\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "704ec7c9-eeeb-43f1-8844-b738dfdce4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_KEY'] = \"***\"\n",
    "groq_api_key = \"***\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250e683c-1000-42f2-8936-73462b3857ec",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Implementing RAG with Multi-query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8bfbe603-40eb-4af3-b15e-29ca10541e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data\n",
    "test_dataset = pd.read_csv(\"random_dataset.csv\")\n",
    "loader = DataFrameLoader(test_dataset, page_content_column='statement')\n",
    "orig_test_documents = loader.load()\n",
    "\n",
    "# sample queries\n",
    "questions = ['Do Best Buy employees feel understaffed?', 'What are the most common reasons for employees to leave Best Buy?', 'What do Best Buy employees think of the company?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "939b37b0-ae11-4790-bbe4-d0d5526f4ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=300, \n",
    "    chunk_overlap=50)\n",
    "# Make splits\n",
    "orig_test_documents_splits = text_splitter.split_documents(orig_test_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb07b59-bdbc-4d61-816c-429f7f632ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Index\n",
    "print(\"indexing ...\")\n",
    "vectorstore = Chroma.from_documents(documents=orig_test_documents_splits, embedding=OpenAIEmbeddings())\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e8727c7-2b81-46cf-841a-69ec8bea7aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi Query: Different Perspectives on the same query \n",
    "template = \"\"\"Given the question below, generate five different variants of the same question. Original question: {question}\"\"\"\n",
    "prompt_perspectives = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "llm = ChatGroq(temperature=0, groq_api_key=groq_api_key, model_name='mixtral-8x7b-32768')\n",
    "\n",
    "generate_queries = (\n",
    "    prompt_perspectives \n",
    "    | llm\n",
    "    | StrOutputParser() \n",
    "    | (lambda x: x.split(\"\\n\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0622299c-aa43-4d0a-bd29-ebb8e8c4bf0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_queries=[]\n",
    "for question in questions:\n",
    "    ques_chain = generate_queries\n",
    "    queries = ques_chain.invoke({\"question\":question})\n",
    "    multi_queries.append(queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33201fb2-ecfe-478b-8fc1-6c8e561fb33f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['1. Are Best Buy employees experiencing a lack of sufficient staffing?',\n",
       "  '2. To what extent do Best Buy employees perceive there to be inadequate staffing levels?',\n",
       "  '3. How often do Best Buy employees feel that there are not enough staff members to handle the workload?',\n",
       "  '4. Do Best Buy employees report feeling overwhelmed by the workload due to insufficient staffing?',\n",
       "  '5. Is there a general consensus among Best Buy employees that the company is understaffed?'],\n",
       " ['1. What are the primary factors that frequently lead to employee turnover at Best Buy?',\n",
       "  '2. Can you identify the most prevalent causes of staff departure from Best Buy?',\n",
       "  '3. What are the top reasons that have been observed for employees leaving Best Buy?',\n",
       "  '4. What are some of the most recurring motives for employees to resign from Best Buy?',\n",
       "  '5. Can you enumerate the most frequent reasons for employee attrition at Best Buy?'],\n",
       " ['1. What are the thoughts of Best Buy employees regarding the company they work for?',\n",
       "  '2. How do employees at Best Buy perceive the company?',\n",
       "  \"3. In the opinion of Best Buy's employees, what is their view of the company?\",\n",
       "  '4. What is the attitude of Best Buy workers towards the company?',\n",
       "  '5. How does the company, Best Buy, fare in the eyes of its employees?']]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a41c882-06ed-4812-95c2-22f747f51df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retreive\n",
    "q1_retrive_documents = [vectorstore.similarity_search_with_score(query,k=20) for query in multi_queries[0]]\n",
    "q2_retrive_documents = [vectorstore.similarity_search_with_score(query,k=20) for query in multi_queries[1]]\n",
    "q3_retrive_documents = [vectorstore.similarity_search_with_score(query,k=20) for query in multi_queries[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7fd4260b-0c9c-4b95-b4cf-884024dd8b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten and sort the retreived doc by similarity score\n",
    "q1_retrive_documents_final = sorted([item for sublist in q1_retrive_documents for item in sublist], key=lambda x:x[1])\n",
    "q2_retrive_documents_final = sorted([item for sublist in q2_retrive_documents for item in sublist], key=lambda x:x[1])\n",
    "q3_retrive_documents_final = sorted([item for sublist in q3_retrive_documents for item in sublist], key=lambda x:x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db1aa106-ac27-426c-a039-f7799d36d58a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove all duplicate docs\n",
    "\n",
    "present_ids = set()\n",
    "q1_retrive_documents_final_final = []\n",
    "for doc in q1_retrive_documents_final:\n",
    "    if doc[0].metadata[\"reddit_id\"] not in present_ids:\n",
    "        present_ids.add(doc[0].metadata[\"reddit_id\"])\n",
    "        q1_retrive_documents_final_final.append(doc)\n",
    "\n",
    "present_ids = set()\n",
    "q2_retrive_documents_final_final = []\n",
    "for doc in q2_retrive_documents_final:\n",
    "    if doc[0].metadata[\"reddit_id\"] not in present_ids:\n",
    "        present_ids.add(doc[0].metadata[\"reddit_id\"])\n",
    "        q2_retrive_documents_final_final.append(doc)\n",
    "len(q2_retrive_documents_final_final)\n",
    "\n",
    "present_ids = set()\n",
    "q3_retrive_documents_final_final = []\n",
    "for doc in q3_retrive_documents_final:\n",
    "    if doc[0].metadata[\"reddit_id\"] not in present_ids:\n",
    "        present_ids.add(doc[0].metadata[\"reddit_id\"])\n",
    "        q3_retrive_documents_final_final.append(doc)\n",
    "len(q3_retrive_documents_final_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "97be1467-7996-4f33-8770-e4a48ca50e50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[doc[0].metadata['Question 1'] for doc in q1_retrive_documents_final_final[:20]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "56fc1706-3a81-4635-8969-55172944c108",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[doc[0].metadata['Question 2'] for doc in q2_retrive_documents_final_final[:20]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "062eb3e3-08ba-4279-aecc-8344933d525d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[doc[0].metadata['Question 3'] for doc in q3_retrive_documents_final_final[:20]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9fe45ee6-c548-4294-a948-804711fa20b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "MQRAGQ1 = [1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0]\n",
    "MQRAGQ2 = [1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0]\n",
    "MQRAGQ3 = [1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0dac4f-d828-4f6c-9496-7c428648e26d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## To compare with baseline retreiver we remove the multi-query part below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "75c93175-5fa8-42d5-9ec0-8b3b40effc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "q1_retrive_documents_simple = vectorstore.similarity_search_with_score(questions[0],k=20)\n",
    "q2_retrive_documents_simple = vectorstore.similarity_search_with_score(questions[1],k=20)\n",
    "q3_retrive_documents_simple = vectorstore.similarity_search_with_score(questions[2],k=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c83c09d1-ac1c-423a-a7af-113788874ba4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[doc[0].metadata['Question 1'] for doc in q1_retrive_documents_simple]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1a714053-0c70-492f-a7e6-bcdb769ed065",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[doc[0].metadata['Question 2'] for doc in q2_retrive_documents_simple]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "35e081bd-c9be-4a6a-94f6-aec682697f1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[doc[0].metadata['Question 3'] for doc in q3_retrive_documents_simple]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e7a285a4-b3cc-4e37-8736-78568f0d9f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "baselineRAGQ1 = [1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1]\n",
    "baselineRAGQ2 = [1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1]\n",
    "baselineRAGQ3 = [1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07850c4-0b2f-4204-a26c-f92cfc9905b9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Final evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ee6d6ee7-e940-48ba-ad5e-7edff2af744f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(lis, k):\n",
    "    \n",
    "    number_of_relevant_item_retreived_k = sum(lis[:k])\n",
    "    total_relevant = sum(lis)\n",
    "    \n",
    "    recall = number_of_relevant_item_retreived_k/total_relevant\n",
    "    prec = number_of_relevant_item_retreived_k / k\n",
    "    f1_score = 2*prec*recall/(prec+recall)\n",
    "\n",
    "    # print('prec : ', prec, '  recall : ', recall, ' f1_score : ', f1_score)\n",
    "    return prec, recall, f1_score\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "826c8960-b386-4230-a286-4053d8aa7d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "BL_metrics_q1 = [evaluate(baselineRAGQ1, i) for i in range(5,21,5)]\n",
    "MQ_metrics_q1 = [evaluate(MQRAGQ1, i) for i in range(5,21,5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7e26bb4b-6a57-465e-b2d6-a36a92c371fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "BL_metrics_q2 = [evaluate(baselineRAGQ2, i) for i in range(5,21,5)]\n",
    "MQ_metrics_q2 = [evaluate(MQRAGQ2, i) for i in range(5,21,5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b32b2177-054b-43d9-87ba-fc0b68052b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "BL_metrics_q3 = [evaluate(baselineRAGQ3, i) for i in range(5,21,5)]\n",
    "MQ_metrics_q3 = [evaluate(MQRAGQ3, i) for i in range(5,21,5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dfd0e9ba-b73e-4ab3-a679-a1eace3cfd94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.35130719, 0.60549595, 0.74135124, 0.7491854 ])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "(np.array([met[2] for met in BL_metrics_q1]) + np.array([met[2] for met in BL_metrics_q2]) + np.array([met[2] for met in BL_metrics_q3]) )/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9e48f1a5-07a1-4957-8ae2-eb71153a1ff4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.3995098 , 0.64646465, 0.77492877, 0.73655914])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.array([met[2] for met in MQ_metrics_q1]) + np.array([met[2] for met in MQ_metrics_q2]) + np.array([met[2] for met in MQ_metrics_q3]) )/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8265eb3c-967a-4780-901b-c191e77accce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
